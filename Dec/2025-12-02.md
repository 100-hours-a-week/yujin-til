## 📆 2025-12-02

### 🔔 스크럼

- Kubernetes Pod와 리소스, 네트워킹 강의 복습 및 정리
- 게시물 이미지 처리 S3 Presigned URL 방식으로 수정

### 🚀 Today I Learned

#### Pod - Probe

- 컨테이너의 정상적으로 작동하는지(상태) 진단하는 매커니즘
- 애플리케이션에 문제가 생기면 필요한 조치를 자동으로 할 수 있음
  - 안정성, 가용성
- 종류
  - **Startup Probe**
    - 애플리케이션 초기화 과정에서 검증하는 역할
    - 애플리케이션 초기화 시간이 긴 파드에서 잘 사용함
      - 뜨고있는데 오류라고 생각해서 꺼버릴수있는걸 방지를 위해 사용함
      - 주기가 길음
    - 초기화때만 사용하고 끝나면 물어보지않음
    - **실무에서**
      - 라이브니스 프로브의 오작동을 막아줌
      - 스타트업 프로브가 준비됐어라고 OK라고 응답을 받으면 스타트업프로브는 다시 작동하지 않음. 라이브나리드니스한테 넘겨줌
  - **Liveness Probe**
    - 애플리케이션이 정상 실행중인지 “지속적”으로 확인함
    - 비정상인 상태라고 파악되면 “자동복구”
      - 쿠버네티스 안에서 복구 = 삭제
        - 원하는 수량이 3개 → 삭제하는 순간 → 파드 수량 2개 → 자동으로 1개 늘림 ⇒ 이게 자동복구
    - **핵심 기능**
      - 컨테이너 살아있는지 확인
    - **핵심 역할**
      - 데드락 탐지, 무한루프 탐지
        - CPU 열심히 사용하고, 외부에서는 Running으로 표시되어있는데, 요청을 보내면 살아있음 = 좀비 프로세스
        - 이걸 감지하기 위해 많이 쓰임
    - **주의사항**
      - 로직이 복잡할 경우 오히려 리소스 낭비 → 단순하게 짜야함(200 ok 정도로)
  - **Readiness Probe**
    - 애플리케이션이 사용자의 요청을 처리할 준비가 되어있는지 주기적으로 체크
    - **실무적으로**
      - 배포할때 많이 사용함. 특히 무중단
      - Readiness Probe응답이 오기전까지 해당 파드에 트래픽 안줘야함
      - v1파드 돌고있고
        - v2파드를 무중단 배포할때
        - 앤드포인트 포인트에 추가함
      - v1 파드는?
        - 라벨설정을 해놓고
        - v2가 트래픽 다가져가서 테스트 끝나면 v1파드는 삭제
- 진단 방법
  1. httpGet
     1. 가장 흔함
     2. 특정 url경로로 http Get요청 보내기
     3. 응담 코드가 200-399 사이면 오케이
  2. TcpSocket
     1. 특정 포트에 TCP연결시도
     2. 성공하면 OK
        1. 웹서버가 아닌경우는 이렇게감
  3. exec
     1. 컨테이너 내부에 특정 명렁어 입력
     2. 명령어의 종료 코드가 0이면 정상으로 판단
- 사용이유 : 상태를 지속적으로 감지하여 안정성과 가용성을 보장하기 위해

##### Liveness vs Readness차이

|        | Liveness                                            | Readness                                    |
| ------ | --------------------------------------------------- | ------------------------------------------- |
| 목적   | 지속적인 생존확인                                   | 트래픽 처리 가능 여부                       |
| 실패시 | 컨테이너 삭제 → 재요청                              | service 목록에서 제외                       |
| 유의   | 파드를 죽이는것이 아님(컨테이너는 파드 내부에 존재) | 파트, 컨테이너 살아있지만 트래픽만 안주는것 |
| 예시   | 데드락 탐지, 무한루프 탐지                          | 롤링 배포, DB 연결대기                      |

#### Namespace

- 하나의 클러스터 안에서 여러 환경(개발, 운영 등)을 독립적으로 관리할 수 있는 기반을 제공함
- 초기에는 잘 나눠서 시작 안함
- 트래픽을 분리한다
- 네임스페이스간에 자원을 할당 시킨다
  - 클러스터에는 자원이 일반적으로 정해져있다 → 각 스페이스별로 자원량을 할당 시킬 수 있음
  - ex) MSA조직일때 팀별로 네임스페이스를 쪼개서 자원을 할당하여 실수를 한다고해도 다른 팀에 피해가 안감

#### ConfigMap

- 쿠버네티스 환경에 맞춰 확장된 dotenv → 키-값형태로 저장하여 Pod에 동적으로 주입하거나 환경변수로 전달하는 쿠버네티스 리소스
- ConfigMap은 Github에 올라감 → 올라갈수 있는 애들만 적어여함
- Pod와 독립적으로 관리됨
- 주입방식
  - 환경변수 → 길어져서 관리 힘듬, 변경시 재시작해야 반영됨
  - 커맨드라인 인수 : 실행시 인수로 전달
  - 볼륨 마운트(실무에서 제일 많이 사용함) : 파일 시스템의 파일로 주입, 변경시 즉시 반영
- 실무에서는 로그, 기능 활성화 플래그, 메모리 제한값, 외부 API 엔드포인트를 적음

#### Secret

- 민감한 데이터를 안전하게 저장하고 Pod에 전달하기 위해 설계된 키-값 쌍의 리소스
- Base64로 인코딩했다고 가정함 → 값이 변화되지않은 것을 검증하기 위해 사용
  - secret.yaml에 인코딩된 값을 넣어야 동작함!
  - 암호화가 아님 → secret.yaml은 깃헙에 업로드하면 안됨!
  - echo -n “인코딩 하고싶은 값” | base64 (-d 디코딩)
- 파일마운트를 통해 갱신되더라도, 애플리케이션이 reload를 지원해야 실제로 반영됨
- 보안요소
  - 값 자체는 인/디코딩이지만 etcd에 들어가면 암호화되어 들어감
  - 접근 통제(RBAC)

##### ConfigMap vs secret

|      | ConfigMap                  | Secret                    |
| ---- | -------------------------- | ------------------------- |
| 목적 | 일반적 설정, 데이터 저장   | 비밀 정보를 저장해서 관리 |
| 예시 | 커맨라이느 외부API, 플래그 | DB비전, APi키. 인증서 TLS |
| 보안 | 없음                       | etcd, RBAC                |

#### Volume

- 컨테이너 파일 시스템을 확장하거나 공유하기 위해 사용되는 데이터 저장소
- = docker volume
- pod → 영속저이지않음.
- 파드 내에 위치한거임
- 컨테이너는 비영속적인 특징, 파드 안에서 컨테이너간의 데이터 공유, 컨테이너 종료 시에도 파드가 살이 있으면, 분리되어있는 볼륨을 사용할 수 있다.
- 사용이유 : 컨테이너의 일시적은 특성을 보완하고, 데이터의 영속성 보장 및 공유를 하기 위해
- 특징
  - 파드랑 수명이 같음 ← 파드 내에 위치한거니까
    - 컨테이너와는 다름. ← 파드 내에 볼륨 & 컨테이너 분리되어 위치해있으니까
    - 파드 삭제 = 일반 볼륨도 같이 삭제
  - 볼륨이 컨테이너 안에서는 “디렉터리”
    - 볼륨 ← 파드 내 컨테이너들 접근
    - 컨테이너 파일 시스템처럼 = 마운트
  - 데이터 보존 + 공유
    - 컨테이너들에게는 데이터가 보존,공유되는걸로 보임
- 볼륨 유형
  1. emptyDir
     - 파드가 새롭게 만들어질때 같이 만들어지는 빈 디렉토리
     - 파드 내에 여러 컨테이너랑 함께 사용함
       - 데이터 공유하거나
       - 임시 데이터 저장소
     - 사용 사례
       - 파드 내에서 임시 캐시 저장소
       - 파드 내에서 컨테이너들끼리 파일 공유하기
       - 로그 데이터 임시 저장
     - 파드 삭제하면
       - emptyDir ← 삭제됨
  2. hostPath
     - 노드에 있는 파일 시스템, 특정 경로 /etc/var/~~/api-ley.txt
       - 파드 안에 불륨으로 마운트
     - 주로 특정 호스트, 특정 파일을 애플리케이션(파드) 사용할때 사용함
     - 쿠버네티스에서는 많이 사용되는 패턴은 아님
       - 왜?
         - 파드는 특정 노드에 생성되지 않는다(일반적으로)
         - 노드 = 컴퓨터, 그러면 모든 컴퓨터에 들어올지말지도 모르는 파드 유형때문에 파일시스템에 게속 뭔가 저장해야함

##### 실무사례

- Empty Dir
  - 사이드카 패턴일때 많이 사용
    - 파드안에 메인(웹서버), 사이드카 컨테이너(로깅) 존재
      - 웹서버 컨테이너는 로그를 볼륨에다가 파일로 던지고
      - 로깅 컨테이너는 로그 파일을 확인해서 새로운 로그 잡히면, 로그 수집하는 곳에 던짐
    - 이때의 볼륨을 Empty Dir로 함
      - 메인 컨테이너 → 쓰기
      - 사이트 컨테이너 → 읽음
      - 고속 데이터 공유가능 → 파드 내에 스토리지 공유
- hostPath
  - 보통 잘 사용하지 않음
  - 시스템 모니터링 도구 전용

#### PV/PVC

- PV : 클러스터 내에서 관리하는 저장공간 → pod, node랑 별도 존재
- 주요 특성
  - 독립성 : 클러스터가 관리하는거라 pod랑 독립적
  - 프로비저닝 : 클러스터 관리자가 사전에 PV를 설정 or 동적으로도 생성가능
- PVC : 파드가 PV 사용하고싶을때 스터리지에 요청하고 바인딩하는 쿠버네티스 리소스
- 주요특성
  - 요청 및 바인딩, Pod와의 연동, 동적 프로비저닝
- PV는 클러스터에서 사전에 준비된 스토리지 리소스이고, PVC는 Pod가 해당 리소스를 요청하고 사용하는 방법
  - 바인딩 이후 PV : PVC = 1:1
- 사용이유
  - PV : Pod의 수명과 독립적으로 데이터를 영구적으로 저장하여 서비스 연속성을 보장하기 위해
  - PVC : Pod가 필요한 스토리지를 추상화된 방식으로 요청하고 사용할 수 있도록 지원하기 위해
- 사용 사례
  - 영속성이 필요한 것(ex. DB)

#### Networking

- 클러스터 내 Pod, 서비스, 외부 네트워크 간의 통신을 관리하고 제어하는 시스템
- 쿠버네티스가 구성하고싶은 네트워크
  - 모든 파드에 IP 부여하자
  - 파드들이 NAT없이 통신하고싶어 ← 왜? 우리 클러스터 내부니까
    - = 플랫네트워크
- 어떻게 구성?
  1. 파드마다 클러스터에 설정한 고유한 CIDR 설정
     - 10.244.00/16
     - 파드 간에 직접 통신이 가능함. 같은 노드든 다른 노드든 대상 파드 IP 부르면 연결
     - NAT 필요없음
  2. 파드는 동적으로 생성,삭제 → IP 주소가 바뀜 → 어떻게 불러? → 서비스 사용 : 파드 앞에서 고정된 IP, DNS 제공 → 엔드포인트(셀럭터, 라벨)로 통신
  3. kube-proxy
     1. 서비스 감시 역할
     2. etcd
        1. 엔트포인트 리스트 들어가있음
        2. master node - API server
           1. kube-proxy가 변동사항을 들고 이걸 iptables에 기록
     3. 노드 안에서 나가는 요청을 가로챔
        1. 가로챈걸 iptables를 검색해서 BGP or VXLAN 방식으로 경로를 알려줌
  4. iptables
- 네트워크 방식
  - BGP : 각 pod들이 자기랑 통신할 수 있는 pod들한테 어떤 pod가 생겼다는걸 계속 알려주는거임. 자신이 들은 소문을 자신의 라우팅 테이블에 적음.
    - 이렇게 하면 NAT 필요없음.
    - P2P로 라우팅을 업데이트 하는 방식
    - 실무에서 사용
    - 이거하려면 라우터,스위치 등 같은 별도의 장비들 필요 & 리소스 많이 필요함
  - VXLAN
    - 중앙 시스템에 노드의 주소지를 대역대 형식으로 등록

##### [쿠버네티스의 실제 네트워크 과정]

##### 1단계 - 내가 어디로 가야될지의 과정(BGP든 VXLAN든 같음)

1. 파드의 생성 → IP받음
2. kubelet한테 보고 (생성잘됐고요,ip는 얼마임)
3. Master Node API Server한테 전달
4. Master Node가 etcd에 기록
5. 마스터 노드 → 모든 노드의 kube-proxy에게 공지
   - 서비스 엔드포인트 업데이트 됐다고 방송함
6. 듣고있던 다른 노드의 kube proxy가 수신
7. 그 다른 노드가 iptables에 기록

##### 2단계 - VXLAN 버전

1. 출발 Pod A → 목적지는 10.244.2.2
   - 노드 A야 나 저기로가야하는데, 어떻게 감? 알아서 통신해주세요 = 격리되어있음
2. 노드A가 kube-proxy가 들고있던 iptables에서 찾아봄 → Node B로 일단 가야될거같은데?
3. 포장
   - 10.244.2.2 ← 원래 내용(Inner TCP)
   - Node B로 가달라라고 포장함 → Outer UDP
4. 전송
   - VXLAN(UDP 터널) 던짐
   - 포트번호 8472
5. 노드 B 도착
6. 언박싱
   - 언박싱하면 10.244.2.2로 가달라고 써있음
7. Pod D 에게 전달

### 🔥 오늘의 도전 과제와 해결 방법

- 게시물 이미지 업로드 방식을 기존 Multipart → S3 Presigned URL 방식으로 전면 교체
  - 프론트에서 이미지 S3 업로드 후 key·원본파일명·사이즈·MIME 타입을 서버로 전달하도록 구조 변경
  - 이미지 변경 없음 → 기존 이미지 그대로 유지
  - 이미지 변경 발생 → 기존 이미지 DB soft delete + S3 파일 삭제 후 새 이미지 저장
  - 백엔드 파일 처리 로직 통합 및 정리
  - createPostFile, replacePostImage, getPostImagesForEdit 등 기능별 메서드 분리
  - 파일 메타데이터와 S3 key 중심으로 저장 구조 일원화

### 🗨️ 오늘의 회고

- 게시물 이미지 기능을 S3 Presigned URL 방식으로 재정비하면서, 백엔드·프론트 흐름 전체를 다시 정렬하는 작업을 했다. 구조를 바꾸다 보니 고려해야 할 요소가 많았지만, 파일 메타데이터 관리, 기존 이미지 유지/삭제 분기, S3와 DB 상태 동기화 등 서버의 이미지가 어떤 흐름으로 설계되어야 하는지 더 이해하게 되었다.
