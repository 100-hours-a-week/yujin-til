## 📆 2025-12-04

### 🔔 스크럼

- Kubernetes 보안, 모니터링, 운영구성 강의 복습 및 정리
- 서버용 더미데이터 삽입 후 전체 기능 사이클 테스트

### 🚀 Today I Learned

### RBAC(Role-Based Access Control)

- 사용자, 그룹, 또는 서비스 계정이 특정 리소스에 대해 수행할 수 있는 작업을 역할(Role)에 기반해 정의하고 제어하는 접근 제어 메커니즘
- Role Binding : 특정 네임스페이스에서 Role을 사용자나 그룹, 서비스 계정에 할당합니다.
- 클러스터 전체 → ClusterRole, ClusterRoleBinding
- Role은 특정 namespace에 속함. 그 안의 리소스만 관리할 수 있음
- 구성요소
  - API 그룹 : Role이 관리할 리소스의 API 그룹을 정의
  - 리소스 : 접근을 제어할 대상 리소스 명시 ex) pods, deployments
  - 작업 : 해당 리소스에 해대 허용되는 작업 지정 ex) get,list
- 사용자, 그룹, 서비스 계정
  - 사용자
    - 사람, 외부 애플리케이션
    - 클러스터랑 직접 소통
    - 클러스터 외부에서 인증서 ← 인증
  - 그룹
    - 사용자를 묶음
    - devops : edit
    - developer : view-pod
    - auth-team : 공통 권한
    - admin
    - super
      - 만들면 무조건 사고
  - 서비스 계정
    - 사람이 아닌것
      - ex) pods, deployment
    - 프로그램에게 권한을 줘야할때 서비스계정을 만듬
- 주의사항
  - 최소 권한 원칙
    - `*` → 리소스, 액션에 대한 모든 권한을 주는것임
  - 리소스 secret 접근 제한
    - 여기에는 lists,get은 안됨. 상위애한테 줘버려야함

### Service Account

- 클러스터내에있는 파드 등 한테 권한을 부여할 수 있도록 계정을 만들어주는것
- 왜 필요할까?
  - 사람이 아닌데, 왜 권한이 필요할까?
  - 파드들은 24시간 쿠버네티스와 상호작용함
  - 쿠버네티스가 파드들에게 권한을 물어보고, 파드들은 자신을 증명하기 위해 service account사용함
- 왜 만들까?
  - 모든 파드는 디폴트 계정이 자동생성됨
    - 디폴트 계정을 아무런 권한이 없음
    - 전용 서비스 어카운트 있음
  - API 서버와 상호작용 해야함
    - 애플리케이션 스스로 배포/모니터링/로그수집 해야할때 각 서비스 계정을 만들어줘서 해당 권한만 줌

### Helm

- 애플리케이션에 Service, Namespace, Deployment 등을 배포하려고하면 yaml 수정/관리해줘야하는데 쉽지않음 → 쿠버네티스 리소스를 “패키지화”해서 관리하는 패키지 매니저
  - 하나의 패키지로 실행할 수 있게 하여 배포를 쉽게하기 위해 사용함
  - 패키지 매니저? Node.js의 npm같이 소프트웨어 패키지 설치/업데이트/삭제/의존성관리를 자동으로 처리해주는 도구
- 왜 사용할까?
  - 환경별로 yaml생성시에 환경별로 파일이 많아진다. → Helm은 하나의 템플릿을 만들고, values.yaml만들어서 환경변수만 따로 관리
  - 복잡한 앱 설치가 힘드니까 헬름에서는 이미 20개가 넘는 yaml 이런거 만들어주고 순서도 맞춰놓은 패키지 가져와서 쓰면됨
    - 모니터링 도구, 프로메테우스 등 설정하기 위한 설정 yaml파일 필요 & 순서대로 apply해야함
  - 배포했는데, 에러 났을 경우 롤백하기 쉬워짐
    - 애플리케이션이 복잡하니 서로 의존성이 있음.
- Helm Chart
  - 쿠버네티스 애플리케이션을 배포하기 위한 일종의 패키지로, 애플리케이션의 리소스를 정의한 템플릿
  - 헬름으로 패키지 하나를 만든걸 차트라고 부름
- Templates ← 디렉토리
  - 애플리케이션 필요한 리소스들을 정의
    - svc.yaml 템플릿
    - deployment.yaml 템플릿
  - 템플릿 파일들은 values.yaml(변수를 만들어둔곳)에 값을 동적으로 받음
  - 최종적인 쿠버네티스 리소스 파일을 생성
- values.yaml
  - 헬름차트에서 사용하는 설정 값 ex) 이미지 마지막 버전, 복제본 수
  - 배포 시에 필요한 구체적인 값을 지정
- Kustomize → heml이 하는 역할 일부 대체 가능
  - heml은 구멍뚫는 방식, 얘는 overlay 방식

#### Kustomize

- 원본 그림(Base)은 그대로 두고, 그 위에 ‘수정할 부분만 그린 투명 필름(Overlay)’을 겹쳐서 완성본을 만드는 방식

### Ingress

- 클러스터 외부의 HTTP/HTTPS 트래픽을 클러스터 내부의 서비스로 라우팅하는 규칙을 정의하는 리소스
- 인그레스는 클러스터의 단일 진입접 제공
- Ingress는 프로세스가 아니라 규칙임
  - 경로
  - TLS 제공
- Ingress Controller
  - Ingress 규칙을 실행하는 오브젝트
  - Nginx, Apache, Traffic, AWS ALB
  - 클러스터내에서 Pod로 존재
- VPC-CNI기능을 키면, 파드는 클러스터 VPC의 IP가 아니라 AWS VPC의 IP를 들고있어서 외부에서(ALB) 파드 IP로 바로보낼 수 있음 → Ingress COntroller나 Nginx 필요없음 → 비쌈
- 외부 트래픽 문제
  - 내부트래픽은 서비스가 함. 서비스로 외부트래픽하려고하면 문제들이 생김 → 그래서 ingress 사용함
- 외부 HTTP/HTTPS 트래픽 세밀하게 제어하는 용도로 사용
- 비용 낭비 + 라우팅 한계를 극복하기 위해 L7 로드밸런서 역할을 해주는 인그레스

#### 서비스와 인그레스 비교하기

- 서비스
  - 파드를 묶어 네트워크 엔드포인트 사용
  - 4계층 사용(TCP/UDP)
  - nodePort, loadbalancer ← 외부 노출
- 인그레스
  - Http/https 요청을 경로, 도메인 기반 라우팅
  - 7계층 사용(HTTP/HTTPS)
  - 도메인, 경로 기반 트래칙 제어
  - 라우팅, 인증 ,TLS 등 고급제어
- 둘은 대치관계가 아님. 같이 사용해야함 → 기본적으로 서비스가 있어야 인그레스도 쓰고 트래픽 보내는걸 할 수 있다
  - 서비스는 파드 중 누가 받아라
  - 인그레스는 이 url을 어떤 서비스더미가 받아라

### Prometheus

- **모니터링** 및 알람을 위한 오픈소스 시스템
- 클러스터의 숫자를 모으는 수집가? = 매트릭 수집
  - pull 방식으로 데이터 수집→ 프로메테우스가 노드한테가서 상태 체크해서 시간순으로 보여주려고함
- yml파일로 직접 설정할 수 있지만 보통 Helm으로 함

### 로키

- 로그의 일기장
- 하는일
  - 로그를 수집해서 저장함 ← 로그 본문을 그냥 압축 후 저장 → 저렴함
    - 검색은 라벨로 해결
    - ex) namespace : app, test
  - 다른 로그 수집기들은 검색을 편하게 하기 위해 색인해놓음 → 저장비용 매우 비쌈(ex. ELK - Log Stash)

### 그라파나

- 메트릭 + 로그를 시각화해주는 도구 + 대시보드
- prometheus의 메트릭 + 로키의 로그를 그라파나에서 보여주는것
- 특징
  - 데이터 소스연동 좋음
    - 프로메테우스, 로키 뿐아니라 mysql, ElasticSearch, CloudWatch 등
  - 대시보드 잘되어있음
    - 그래프, 파이차트, 게이지, 지도
  - 오픈소스
- yml파일로 직접 설정할 수 있지만 보통 Helm으로 함

### 🗨️ 오늘의 회고

- 개인 프로젝트가 거의 마무리 단계에 들어섰다. 처음에는 막막했지만 하나씩 해결해 나가며 끝까지 구현해내니 뿌듯한 느낌도 단다. 아쉬운 부분들도 보이기 시작해, 마무리 후에는 개선 작업도 진행해볼 생각이다.
