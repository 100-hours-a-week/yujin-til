## 📆 2025-11-11

### 🔔 스크럼

- AWS(배포,트래픽 분산) 강의 복습 및 정리
- 9주차 과제 사전 작업
  - 프론트 프록시 서버 제거에 따른 프론트,백엔드 코드 수정

### 🚀 Today I Learned

#### RDS(Relational Database Service)

- 클라우드에서 관계형 데이터베이스를 손쉽게 생성/운영/확장할 수 있도록 제공하는 완전 관리형 서비스
- 관리형 서비스?
  - 우리가 할 수 있는것들을 AWS같은 클라우드 사업자가 대신 해주고 관리해주고 우리는 비용을 지불함
- 백업본인 스냅샷을 관리해주기도함
- EC2에 비해 가격이 있음
- 사용이유 : DB설치, 패치, 백업 같은 복잡한 관리 직접수행할 필요 X → 사용자들이 애플리케이션 개발과 비즈니스 로직에 집중할 수 있도록 하기 위함
- 관리형 서비스가 항상 인건비를 줄여주는가? 무조건 YES는 아님!
  - 초기 서비스는 맞는데
  - 대형 서비스로 가면 오히려 힘들 수도 있음
- EC2에 직접 DB서버를 구축하면 더 싼데 왜 RDS를 쓸까?
  - EC2에서 직접 DB 서버를 운영하면 패치, 백업, 장애 대응 등을 직접 관리해야함. RDS는 자동화된 백업과 패치, 고가용성 구성을 기본 제공하므로 관리 부담이 적음.
  - 또한 멀티 AZ 배포와 읽기 복제본을 쉽게 설정할 수 있어 데이터베이스의 안정성과 확장성이 뛰어나고, 장기적으로 관리 비용과 리스크가 더 낮음
    - 멀티 AZ? RDS 데이터베이스를 두 개 이상의 서로 다른 가용 영역(AZ)에 자동 복제하여 운영하는 고가용성 구성 방식

#### ElastiCache

- AWS에서 제공하는 관리형 인메모리 캐시 서비스, Redis와 Memcached 엔진 지원함
- 인메모리
  - 정보를 메모리에 들고있다.
- 캐시
  - 자주 접근하는 데이터를 임시로 들고있는것
- 인메모리 캐시
  - Key-value Store가 인메모리 형태를 많이 띄운다
- 데이터베이스와 애플리케이션 사이에 캐시 레이어를 추가하여 자주 조회되는 데이터의 접근 시간을 줄이고, 시스템 성능을 최적화할 수 있도록함
- Global Cache = ElastiCache
- 사용이유 : 운영 관리의 복잡성을 줄이고 자동화를 이용하기 위해

#### ELB(Elastic Load Balancer)

- 여러 대의 서버로 들어오는 네트워크 트래픽을 자동으로 분산해주는 서비스
- “트래픽 분배”에 관심있는게 로드밸런서고, AWS에서 제공해주는 로드밸런서가 ELB
- **로드 밸런서** vs **리버스 프록시**
  - 둘다 클라이언트의 요청을 받아서 내부서버를 전달하는건 맞지만, 목적이 다름
  - **로드밸런서**는 트래픽 분산에 초점이 있고
  - **리버스 프록시**는 요청/응답 중계에 초점이 있음 + 캐싱 작업 + SSL검증
  - **로드밸런싱은 리버스 프록시의 기능 중 하나임**
- 로드밸런싱 알고리즘 : 트래픽 나누는 방법
  - 라운드 로빈 : 요청을 순차적으로 돌리는 방식
  - 최소연결 : 현재 처리 중인 요청의 수가 가장 적은 서버에게 우선 전달
- 실무에서는
  - 초기 : 클라이언트 ↔ “로드밸런서 + 리버스프록시”
    - 이렇게 2가지가 하나의 인스턴스에서 수행되도록 함
    - 돈이 들어가니까
- 로드 밸런서 유형
  - **ALB**(Application Load Balancer) : URL, 파라미터, 쿠키 등 요청에 대한 응용계층에 있는 값들을 보고 트래픽 분배 → 웹사이트 트래픽(HTTP, HTTPS)을 처리
    - 초기에는 보통은 이걸 사용함
      - 왜? domain.com은 웹사이트를 보내주고, domain.com/api는 백엔드 호출해줘야함 → 지금 URL보고 판단하니까
  - NLB(Network Load Balancer) : 요청이 온 IP + Port를 보고 트래픽을 분배해줌 → TCP,UDP같은 네트워크 트래픽을 처리
- 사용이유 : 서버 간 트래픽을 자동 분산해 장애 시에도 서비스 가용성을 유지하고 안정적인 성능을 보장하기 위해
  - 핵심 이유는 **트래픽 관리 및 부하 분산**
  - 로드밸런서는 헬스체크를 하니까(살아있나 계속 체크) 장애조치 가능
- 가용영역은 2개 이상 선택해야함
  - 왜? 가용영역이 하나가 터지만 다른쪽으로 가야하니까.
- route53을 바꿔서 로드밸런서를 보게 하는것
- Auto Scaling 연동
  - ELB는 EC2 Auto Scaling과 연동하여 트래픽 증가 및 감소에 따라 서버를 자동으로 확장하거나 축소할 수 있음

#### CloudFront

- 전 세계에 분산된 서버 네트워크(CDN)를 통해 사용자에게 콘텐츠를 빠르고 안전하게 전달하는 서비스
- CDN을 AWS가 제공하는걸 CloudFront라고함.
- S3, EC2(원본서버)에 리소스를 직접 요청하지 않고, 콘텐츠 캐시서버를(CDN) 두어 인스턴스에 직접 매번 접근하지 않도록하기 위함
- S3가 비싸니까 CloudFront를 두어 트래픽비용이 덜나가서 비용 효율적임
- 유의할점
  - 캐싱되어있는(CDN)에 들어가있는 파일이 바뀔때 무효화 시켜줘야함→ 무효화 설정을 잘해야함
  - 배포할때마다 무효화하는 코드들을 스크립트화 시켜놓으면 됨

#### API Gateway

- 클라이언트와 백엔드 서비스 사에에서 API 요청을 관리/변환/보호해주는 완전관리형 서비스
- 사용 이유 : 백엔드-클라이언트 간의 통신을 중재하고, API 관리, 보안, 성능 최적화를 위해 사용
- RP, LB랑 뭐가 다르지?
  - RP : 요청을 중계하고 전달
    - 요청이 오면
      - 이거 누가 받아야하는지?
  - LB : 트래픽을 분배하는것에 관심
- api gateway?
  - 이 API를 어떤애가 받을래?
    - 어떤 엔드포인트가 받을래?
    - Rest API
      - /users
      - /posts
      - ex ) 이 요청은 /users/me네? WAS의 유저가 처리해야하고, /posts 면 람다가 처리해야하네?
      - 각 WAS들이 마이크로서비스로 되어있는 경우에 많이 쓰고, api url을 더 자세하게 봄. 아예 다른서비스에 보낼때도 api gateway쓰면 다른서비스로도 감
  - 특히 서버리스 백엔드와 같이 많이 쓰임

#### 핵심차이

- 리버스 프록시 : 백엔드 서비스나 엔드포인트를 엄폐, 요청과 응답의 중계에 관심
- 로드밸런서 : 트래픽에 따라 단일 서비스에 트래픽 분산
- API 게이트웨이 : 마이크로 서비스 혹은 서버리스에서 사용. 다양한 서비스에 요청을 전달할 때. 단일 진입점으로 사용

### 🔥 오늘의 도전 과제와 해결 방법

- 다중서버 배포를 위해 Express 프록시(api.js) 제거 후, 브라우저에서 백엔드(Spring Boot)로 직접 API 호출 시 CORS·JWT 인증 문제 발생
  - 백엔드에 CORS 정책을 명확히 적고, JWT 인증을 Authorization 헤더 대신 HttpOnly 쿠키 기반으로 전환하여 직접 통신 구조 완성함

### 🗨️ 오늘의 회고

- ELB를 적용하면서 Express 프록시 서버를 걷어냈다. 전에는 /api 요청을 직접 중계하는 코드를 한 줄 한 줄 작성했는데, 이제는 ELB가 그 역할을 인프라 레벨에서 대신 처리한다는 점이 인상적이었다.
- 직접 구현하던 로직이 “서비스 레벨”이 아니라 “클라우드 인프라 레벨”에서 자동으로 동작하는 걸 보며, 프록시와 라우팅의 책임이 애플리케이션에서 인프라로 옮겨진다는 개념을 느낄 수 있었다.
